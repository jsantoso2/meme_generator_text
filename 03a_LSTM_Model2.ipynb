{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03a_Model2v1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvoeZ0k5QdW4MSETRAdH68"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"30539e5cdb0c461a90adc6d8cbd56d20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9d97de87b3024222a1252f8991c5a9eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_851d0e0b8d514e989aefece9a4fcd44d","IPY_MODEL_fcdaf4d80c0843c5a2fc694af6ac0a01"]}},"9d97de87b3024222a1252f8991c5a9eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"851d0e0b8d514e989aefece9a4fcd44d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_10c194661386401d99bb34ab9e266410","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3384862a305f4186a80fd6c8ca694c89"}},"fcdaf4d80c0843c5a2fc694af6ac0a01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cb8627ae6ac448d69e5fada4afa86928","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [1:25:22&lt;00:00,  1.17s/it, NLL=1.52]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4391d5bf02347f998db0bbf5c06a5c9"}},"10c194661386401d99bb34ab9e266410":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3384862a305f4186a80fd6c8ca694c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb8627ae6ac448d69e5fada4afa86928":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f4391d5bf02347f998db0bbf5c06a5c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35308ebc710947728b82f1f064a878d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe4de7a51bda4a31a2552a7e2181af22","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42d22e0c956748d4beb623a9cedd6a5c","IPY_MODEL_3b610ceaa65e43619350f7a760f9cdb8"]}},"fe4de7a51bda4a31a2552a7e2181af22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42d22e0c956748d4beb623a9cedd6a5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c0b9057d714a4267b1a889cff933c562","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6feaba19337940b39d9cf17c5b9fb987"}},"3b610ceaa65e43619350f7a760f9cdb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e13a1de8a254a81bd43894322a21227","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [42:37&lt;00:00,  1.71it/s, NLL=1.39]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65eccd90cd554a71a8b029bbf2dddef4"}},"c0b9057d714a4267b1a889cff933c562":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6feaba19337940b39d9cf17c5b9fb987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e13a1de8a254a81bd43894322a21227":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"65eccd90cd554a71a8b029bbf2dddef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b894da7e9ba147d99655a89ac64b6537":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9ec61fcc675249b0bd1bbac89918dcc2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ba63995889f42dfb1528b8296d0cc65","IPY_MODEL_f1fe33c4c92649cabf05802c0065b148"]}},"9ec61fcc675249b0bd1bbac89918dcc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ba63995889f42dfb1528b8296d0cc65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9cfe0e0c778b46d284ab253b27acaff1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18c4994c87074a82b79964345726b8bc"}},"f1fe33c4c92649cabf05802c0065b148":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8bc2326206b54b87bef076087c00dff0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [41:42&lt;00:00,  1.75it/s, NLL=1.33]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5bb2773d67c64b158737c017c075568e"}},"9cfe0e0c778b46d284ab253b27acaff1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"18c4994c87074a82b79964345726b8bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bc2326206b54b87bef076087c00dff0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5bb2773d67c64b158737c017c075568e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e22b02107997484496210feb79824016":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_af977c6d5c5c4ef6ad6c9623847c1960","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1c6eef2868f43289c83d0600a7aa933","IPY_MODEL_d530605c76ea43c492d7440ba131adc5"]}},"af977c6d5c5c4ef6ad6c9623847c1960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1c6eef2868f43289c83d0600a7aa933":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d9689b81965410e9caa7457aaedc807","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7a3fd5bbdbf4b1397b0ebe009086ef2"}},"d530605c76ea43c492d7440ba131adc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6786fba8351493b82b9f2652e804b83","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [1:27:18&lt;00:00,  1.20s/it, NLL=1.29]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b595699deeb0436eaa50131054801813"}},"7d9689b81965410e9caa7457aaedc807":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c7a3fd5bbdbf4b1397b0ebe009086ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6786fba8351493b82b9f2652e804b83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b595699deeb0436eaa50131054801813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a96fb27e8373493c9d56266632f210b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73c888ff306b4cdfb4c527a8b35bc019","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_63c64fd5a38d4d8292c7a34dd0ca97bb","IPY_MODEL_b8357e48d00a4726baf6307474543e6a"]}},"73c888ff306b4cdfb4c527a8b35bc019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63c64fd5a38d4d8292c7a34dd0ca97bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e65c03b3d95f43da85e7520b831903c5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7ccdb38321b4a61a952d70b12770e1a"}},"b8357e48d00a4726baf6307474543e6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e586d163687e49108438171cd5d1fbf6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [44:09&lt;00:00,  1.65it/s, NLL=1.27]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9ff9765d9dd49cf94c7963fe8c590a9"}},"e65c03b3d95f43da85e7520b831903c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e7ccdb38321b4a61a952d70b12770e1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e586d163687e49108438171cd5d1fbf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b9ff9765d9dd49cf94c7963fe8c590a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11f3e5f738a74cae9025f934945424e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_810af9a64e684d6faaefa7c1afbd099e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_75d6df3b736c4048aadf9550aad8a8ab","IPY_MODEL_11ea7277c375410d89ac3c0c60823018"]}},"810af9a64e684d6faaefa7c1afbd099e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75d6df3b736c4048aadf9550aad8a8ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d83f37abd3545fba66f5a42246127e8","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1510a1078a0b4768bc07861162d0638d"}},"11ea7277c375410d89ac3c0c60823018":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_95b6168b927545a9b1a95ceabf02de2c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [41:14&lt;00:00,  1.77it/s, NLL=1.25]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9162ecec081d40758c7d60c96d0bbad0"}},"8d83f37abd3545fba66f5a42246127e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1510a1078a0b4768bc07861162d0638d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95b6168b927545a9b1a95ceabf02de2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9162ecec081d40758c7d60c96d0bbad0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fde75d766cb47688a2c4d6183adec5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d423007d5f514d57937c616f8cf97fa1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a453e98ea2fa47a399af593b29cbc8da","IPY_MODEL_7b074653d51f472ba525cd4f77691739"]}},"d423007d5f514d57937c616f8cf97fa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a453e98ea2fa47a399af593b29cbc8da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7a9409c9c0914644bd51fa78de5ba2ac","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6ccbec5d1524c178d845b77594ff7fc"}},"7b074653d51f472ba525cd4f77691739":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7bcf79c8419c45a2806efd2772b0de72","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [43:33&lt;00:00,  1.68it/s, NLL=1.24]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3635e14f50f4dd89c18edfbcdc400c5"}},"7a9409c9c0914644bd51fa78de5ba2ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e6ccbec5d1524c178d845b77594ff7fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bcf79c8419c45a2806efd2772b0de72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f3635e14f50f4dd89c18edfbcdc400c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"973477ae2c234469a7b6dfb19b2c01b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_98abd0cf329d45fbad46126f9aae7854","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_018b4982106c48a3b88f9cda1864e701","IPY_MODEL_f347ce312a6f442a90aefb7fd82c178a"]}},"98abd0cf329d45fbad46126f9aae7854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"018b4982106c48a3b88f9cda1864e701":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c151c54e64aa4fe28d471dd0e4091420","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b853590b17304da9aab4259712eefa08"}},"f347ce312a6f442a90aefb7fd82c178a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ebddce01e494267a689e0dd0f715bb6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [45:17&lt;00:00,  1.61it/s, NLL=1.23]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15a97f5992d8424ba3c3abc265ebaaf9"}},"c151c54e64aa4fe28d471dd0e4091420":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b853590b17304da9aab4259712eefa08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ebddce01e494267a689e0dd0f715bb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"15a97f5992d8424ba3c3abc265ebaaf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49fba5a1c4ad470088714236f664d6cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eff7df095b8049119d76ccd6a0430632","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_67c1f359ab5a4b129297aaafaf51bafe","IPY_MODEL_8b87d2ff2032490f81805e71323f5d8c"]}},"eff7df095b8049119d76ccd6a0430632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67c1f359ab5a4b129297aaafaf51bafe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5787d56980ab477c920b372df7517bb7","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4383,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4383,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42cd728197bc4acb8f4b449178a3f0fc"}},"8b87d2ff2032490f81805e71323f5d8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfef253774724aee8c74c642af7e3ac9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4383/4383 [01:25&lt;00:00, 51.24it/s, NLL=1.23]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5023def23931494ba0c473c6dc118d1b"}},"5787d56980ab477c920b372df7517bb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"42cd728197bc4acb8f4b449178a3f0fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfef253774724aee8c74c642af7e3ac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5023def23931494ba0c473c6dc118d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"JRzCNWYPQWTc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1600473996348,"user_tz":240,"elapsed":661,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"fcf44c75-d7dc-4174-823a-21ca671b4a01"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Sep 19 00:06:36 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PTXtQJz-Qf3S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1600473999895,"user_tz":240,"elapsed":4163,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"eedfb5c2-27fe-4469-bc4f-19287cb03677"},"source":["!pip install tensorboardX"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\r\u001b[K     |█                               | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vXoyHqixQf_A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600474020402,"user_tz":240,"elapsed":24648,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"a336d340-8207-49bb-b97f-a816bc090c26"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tDv8VA4TQgCO","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2IU8OWVQf8r","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTG56nw4SjsG","colab_type":"text"},"source":["**Data Loader**"]},{"cell_type":"code","metadata":{"id":"6Icoog5FSniS","colab_type":"code","colab":{}},"source":["import torch\n","import torch.utils.data as data\n","import numpy as np\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9_uRAOPSpAX","colab_type":"code","colab":{}},"source":["# read json for dictionary mapping\n","# open from json file for character mapping\n","with open('gdrive/My Drive/MemeGenerator/dataset_final_m2/char2idx.json', 'r', encoding = 'UTF-8') as json_file:\n","    char2idx = json.load(json_file)\n","\n","# open from json file for image mapping\n","with open('gdrive/My Drive/MemeGenerator/dataset_final_m2/img2idx.json', 'r', encoding = 'UTF-8') as json_file:\n","    img2idx = json.load(json_file)\n","\n","idx2char = {value:key for key, value in char2idx.items()}\n","idx2img = {value:key for key, value in img2idx.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-biMm8wSqVg","colab_type":"code","colab":{}},"source":["class MemeDataset(data.Dataset):\n","    \"\"\"Meme Dataset.\n","\n","    Each item in the dataset is a tuple with the following entries (in order):\n","         source = np.array(X_train),\n","         label = np.array(y_train),\n","         img = img_train,\n","         ids = list(range(X_train.shape[0]))\n","    Args:\n","        data_path (str): Path to .npz file containing pre-processed dataset.\n","    \"\"\"\n","    def __init__(self, data_path):\n","        super(MemeDataset, self).__init__()\n","        dataset = np.load(data_path, allow_pickle=True)\n","\n","        self.source = torch.from_numpy(dataset['source']).long()\n","        self.label = torch.from_numpy(dataset['label']).long()\n","        self.img = torch.from_numpy(dataset['img']).long()\n","        self.ids = torch.from_numpy(dataset['ids']).long()\n","\n","        # index\n","        self.valid_idxs = [idx for idx in range(len(self.ids))]\n","\n","    def __getitem__(self, idx):\n","        idx = self.valid_idxs[idx]\n","        example = (self.source[idx],\n","                   self.label[idx],\n","                   self.img[idx],\n","                   self.ids[idx])\n","        return example\n","\n","    def __len__(self):\n","        return len(self.valid_idxs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pD0RIeEESwIU","colab_type":"code","colab":{}},"source":["# traind and dev data loader\n","train_dataset = MemeDataset('gdrive/My Drive/MemeGenerator/dataset_final_m2/train.npz')\n","train_loader = data.DataLoader(train_dataset,\n","                                batch_size=32,\n","                                shuffle=True,\n","                                num_workers=4,\n","                                )\n","\n","dev_dataset = MemeDataset('gdrive/My Drive/MemeGenerator/dataset_final_m2/test.npz')\n","dev_loader = data.DataLoader(dev_dataset,\n","                                batch_size=32,\n","                                shuffle=False,\n","                                num_workers=4,\n","                                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7ryBHwzyiwf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-D1BaMWzWllD","colab_type":"text"},"source":["**Modelling**"]},{"cell_type":"code","metadata":{"id":"YaLx8tmBWkzP","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","from torch.optim.lr_scheduler import StepLR, ExponentialLR\n","\n","import numpy as np\n","import tqdm\n","from collections import OrderedDict\n","from json import dumps\n","import random\n","import os\n","import logging\n","import queue\n","import shutil\n","import string\n","import json\n","\n","random.seed(224)\n","np.random.seed(224)\n","torch.manual_seed(224)\n","torch.cuda.manual_seed_all(224)\n","\n","from tensorboardX import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIMPL1kGWk3y","colab_type":"code","colab":{}},"source":["class AverageMeter:\n","    \"\"\"Keep track of average values over time.\n","\n","    Adapted from:\n","        > https://github.com/pytorch/examples/blob/master/imagenet/main.py\n","    \"\"\"\n","    def __init__(self):\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def reset(self):\n","        \"\"\"Reset meter.\"\"\"\n","        self.__init__()\n","\n","    def update(self, val, num_samples=1):\n","        \"\"\"Update meter with new value `val`, the average of `num` samples.\n","\n","        Args:\n","            val (float): Average value to update the meter with.\n","            num_samples (int): Number of samples that were averaged to\n","                produce `val`.\n","        \"\"\"\n","        self.count += num_samples\n","        self.sum += val * num_samples\n","        self.avg = self.sum / self.count\n","\n","\n","class EMA:\n","    \"\"\"Exponential moving average of model parameters.\n","    Args:\n","        model (torch.nn.Module): Model with parameters whose EMA will be kept.\n","        decay (float): Decay rate for exponential moving average.\n","    \"\"\"\n","    def __init__(self, model, decay):\n","        self.decay = decay\n","        self.shadow = {}\n","        self.original = {}\n","\n","        # Register model parameters\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                self.shadow[name] = param.data.clone()\n","\n","    def __call__(self, model, num_updates):\n","        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                assert name in self.shadow\n","                new_average = \\\n","                    (1.0 - decay) * param.data + decay * self.shadow[name]\n","                self.shadow[name] = new_average.clone()\n","\n","    def assign(self, model):\n","        \"\"\"Assign exponential moving average of parameter values to the\n","        respective parameters.\n","        Args:\n","            model (torch.nn.Module): Model to assign parameter values.\n","        \"\"\"\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                assert name in self.shadow\n","                self.original[name] = param.data.clone()\n","                param.data = self.shadow[name]\n","\n","    def resume(self, model):\n","        \"\"\"Restore original parameters to a model. That is, put back\n","        the values that were in each parameter at the last call to `assign`.\n","        Args:\n","            model (torch.nn.Module): Model to assign parameter values.\n","        \"\"\"\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                assert name in self.shadow\n","                param.data = self.original[name]\n","\n","\n","class CheckpointSaver:\n","    \"\"\"Class to save and load model checkpoints.\n","\n","    Save the best checkpoints as measured by a metric value passed into the\n","    `save` method. Overwrite checkpoints with better checkpoints once\n","    `max_checkpoints` have been saved.\n","\n","    Args:\n","        save_dir (str): Directory to save checkpoints.\n","        max_checkpoints (int): Maximum number of checkpoints to keep before\n","            overwriting old ones.\n","        metric_name (str): Name of metric used to determine best model.\n","        maximize_metric (bool): If true, best checkpoint is that which maximizes\n","            the metric value passed in via `save`. Otherwise, best checkpoint\n","            minimizes the metric.\n","        log (logging.Logger): Optional logger for printing information.\n","    \"\"\"\n","    def __init__(self, save_dir, max_checkpoints, metric_name,\n","                 maximize_metric=False, log=None):\n","        super(CheckpointSaver, self).__init__()\n","\n","        self.save_dir = save_dir\n","        self.max_checkpoints = max_checkpoints\n","        self.metric_name = metric_name\n","        self.maximize_metric = maximize_metric\n","        self.best_val = None\n","        self.ckpt_paths = queue.PriorityQueue()\n","        self.log = log\n","        self._print(f\"Saver will {'max' if maximize_metric else 'min'}imize {metric_name}...\")\n","\n","    def is_best(self, metric_val):\n","        \"\"\"Check whether `metric_val` is the best seen so far.\n","\n","        Args:\n","            metric_val (float): Metric value to compare to prior checkpoints.\n","        \"\"\"\n","        if metric_val is None:\n","            # No metric reported\n","            return False\n","\n","        if self.best_val is None:\n","            # No checkpoint saved yet\n","            return True\n","\n","        return ((self.maximize_metric and self.best_val < metric_val)\n","                or (not self.maximize_metric and self.best_val > metric_val))\n","\n","    def _print(self, message):\n","        \"\"\"Print a message if logging is enabled.\"\"\"\n","        if self.log is not None:\n","            self.log.info(message)\n","\n","    def save(self, step, model, metric_val, device):\n","        \"\"\"Save model parameters to disk.\n","\n","        Args:\n","            step (int): Total number of examples seen during training so far.\n","            model (torch.nn.DataParallel): Model to save.\n","            metric_val (float): Determines whether checkpoint is best so far.\n","            device (torch.device): Device where model resides.\n","        \"\"\"\n","        ckpt_dict = {\n","            'model_name': model.__class__.__name__,\n","            'model_state': model.cpu().state_dict(),\n","            'step': step\n","        }\n","        model.to(device)\n","\n","        checkpoint_path = os.path.join(self.save_dir,\n","                                       f'step_{step}.pth.tar')\n","        torch.save(ckpt_dict, checkpoint_path)\n","        self._print(f'Saved checkpoint: {checkpoint_path}')\n","\n","        if self.is_best(metric_val):\n","            # Save the best model\n","            self.best_val = metric_val\n","            best_path = os.path.join(self.save_dir, 'best.pth.tar')\n","            shutil.copy(checkpoint_path, best_path)\n","            self._print(f'New best checkpoint at step {step}...')\n","\n","        # Add checkpoint path to priority queue (lowest priority removed first)\n","        if self.maximize_metric:\n","            priority_order = metric_val\n","        else:\n","            priority_order = -metric_val\n","\n","        self.ckpt_paths.put((priority_order, checkpoint_path))\n","\n","        # Remove a checkpoint if more than max_checkpoints have been saved\n","        if self.ckpt_paths.qsize() > self.max_checkpoints:\n","            _, worst_ckpt = self.ckpt_paths.get()\n","            try:\n","                os.remove(worst_ckpt)\n","                self._print(f'Removed checkpoint: {worst_ckpt}')\n","            except OSError:\n","                # Avoid crashing if checkpoint has been removed or protected\n","                pass\n","\n","def load_model(model, checkpoint_path, gpu_ids, return_step=True):\n","    \"\"\"Load model parameters from disk.\n","\n","    Args:\n","        model (torch.nn.DataParallel): Load parameters into this model.\n","        checkpoint_path (str): Path to checkpoint to load.\n","        gpu_ids (list): GPU IDs for DataParallel.\n","        return_step (bool): Also return the step at which checkpoint was saved.\n","\n","    Returns:\n","        model (torch.nn.DataParallel): Model loaded from checkpoint.\n","        step (int): Step at which checkpoint was saved. Only if `return_step`.\n","    \"\"\"\n","    device = f\"cuda:{gpu_ids[0] if gpu_ids else 'cpu'}\"\n","    ckpt_dict = torch.load(checkpoint_path, map_location=device)\n","\n","    # Build model, load parameters\n","    model.load_state_dict(ckpt_dict['model_state'])\n","\n","    if return_step:\n","        step = ckpt_dict['step']\n","        return model, step\n","\n","    return model\n","\n","def get_logger(log_dir, name):\n","    \"\"\"Get a `logging.Logger` instance that prints to the console\n","    and an auxiliary file.\n","\n","    Args:\n","        log_dir (str): Directory in which to create the log file.\n","        name (str): Name to identify the logs.\n","\n","    Returns:\n","        logger (logging.Logger): Logger instance for logging events.\n","    \"\"\"\n","    class StreamHandlerWithTQDM(logging.Handler):\n","        \"\"\"Let `logging` print without breaking `tqdm` progress bars.\n","\n","        See Also:\n","            > https://stackoverflow.com/questions/38543506\n","        \"\"\"\n","        def emit(self, record):\n","            try:\n","                msg = self.format(record)\n","                tqdm.tqdm.write(msg)\n","                self.flush()\n","            except (KeyboardInterrupt, SystemExit):\n","                raise\n","            except:\n","                self.handleError(record)\n","\n","    # Create logger\n","    logger = logging.getLogger(name)\n","    logger.setLevel(logging.DEBUG)\n","\n","    # Log everything (i.e., DEBUG level and above) to a file\n","    log_path = os.path.join(log_dir, 'log.txt')\n","    file_handler = logging.FileHandler(log_path)\n","    file_handler.setLevel(logging.DEBUG)\n","\n","    # Log everything except DEBUG level (i.e., INFO level and above) to console\n","    console_handler = StreamHandlerWithTQDM()\n","    console_handler.setLevel(logging.INFO)\n","\n","    # Create format for the logs\n","    file_formatter = logging.Formatter('[%(asctime)s] %(message)s',\n","                                       datefmt='%m.%d.%y %H:%M:%S')\n","    file_handler.setFormatter(file_formatter)\n","    console_formatter = logging.Formatter('[%(asctime)s] %(message)s',\n","                                          datefmt='%m.%d.%y %H:%M:%S')\n","    console_handler.setFormatter(console_formatter)\n","\n","    # add the handlers to the logger\n","    logger.addHandler(file_handler)\n","    logger.addHandler(console_handler)\n","\n","    return logger"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pn4NZg2FSxpt","colab_type":"code","colab":{}},"source":["class MemeGeneratorLSTM(nn.Module):\n","    def __init__(self):\n","        super(MemeGeneratorLSTM, self).__init__()\n","        self.embedding_dim = 128\n","        self.img_embedding = 32\n","        self.seqlen = 1\n","        self.num_classes = len(char2idx)\n","\n","        self.lstm_hidden_size = 1024\n","        self.lstm_layer_size = 1\n","        self.lstm_num_directions = 1\n","        \n","        # Embedding Layer for Images\n","        self.embedding_img = nn.Embedding(len(img2idx), self.img_embedding)\n","        # Embedding Layer for character embeddings\n","        self.embedding_layer = nn.Embedding(len(char2idx), self.embedding_dim, padding_idx = char2idx['<pad>'])\n","        \n","        # project to embedding dim\n","        self.project_down = nn.Linear(self.img_embedding + self.embedding_dim, self.embedding_dim)\n","\n","        # LSTM layer\n","        self.lstm_layer = nn.LSTM(input_size = self.embedding_dim, hidden_size = self.lstm_hidden_size, num_layers=self.lstm_layer_size, bidirectional=False, batch_first = True)\n","        # fc layer\n","        self.fc = nn.Linear(self.lstm_hidden_size, self.num_classes) \n","\n","\n","    def forward(self, input_img, x, prev_state_h, prev_state_c):\n","        # input_img (batch_size)\n","        # x is the decoder input (batch_size, 1) where 1 is seqlen\n","        # prev_state_h (num_layers_dec * num_directions_dec, batch_size, hidden_size_dec)\n","        # prev_state_c (num_layers_dec * num_directions_dec, batch_size, hidden_size_dec)\n","        batch_size = x.size()[0]\n","\n","        # input_img (batch_size, 1)\n","        input_img = torch.unsqueeze(input_img, dim=1)\n","        \n","        # repeat for replication (batch_size, 1)\n","        input_img = input_img.repeat(1,1)\n","\n","        # image embeddings (batch_size, 1, img_embedding_dim)\n","        img_out = self.embedding_img(input_img)\n","\n","        # embedding shape (batch_size, 1, embedding_dim) where 1 is seqlen\n","        text_out = self.embedding_layer(x)\n","\n","        \n","        # concatenate between image and caption embeddings\n","        # (batch_size, 1, text_emb + img_emb) where 1 is seqlen\n","        cat = torch.cat((img_out, text_out), dim=2)\n","\n","        # project down to (batch_size, 1, 128) where 1 is seqlen\n","        embedding_out = self.project_down(cat)\n","\n","        # apply LSTM layer\n","        # HERE IN THE DECODER WE PASS IN SEQ_LEN = 1 to force feed decoder\n","        # input = batchsize x seq_len x input_size -> Here input_size = 128\n","        # lstm_out = (batch, seq_len, num_directions * hidden_size)\n","        # hn = hidden at t=seq_len  (numdirection x num_layers, batchsize, hidden_size)\n","        # cn = cell at t=seq_len (numdirection x num_layers, batchsize, hidden_size)\n","        lstm_out, (hn, cn) = self.lstm_layer(embedding_out, (prev_state_h, prev_state_c))\n","\n","        # output shape before squeeze == (batch_size, 1, hidden_size)\n","        # output shape after squeeze == (batch_size, hidden_size)\n","        output = torch.squeeze(lstm_out, dim = 1)\n","        \n","        # output shape == (batch_size, vocab)\n","        out = self.fc(output)\n","        return out, hn, cn #, attention_weights\n","\n","\n","    def init_state(self, batch_size):\n","        # first one is layer size * num_directions\n","        return (torch.zeros(1, batch_size, self.lstm_hidden_size),\n","                torch.zeros(1, batch_size, self.lstm_hidden_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eqSau64QfGqO","colab_type":"code","colab":{}},"source":["class MemeGeneratorM2(nn.Module):\n","    def __init__(self):\n","        super(MemeGeneratorM2, self).__init__()\n","        self.memegeneratorlstm = MemeGeneratorLSTM()\n","\n","    def forward(self, input_img, x, label, device, prediction_mode = False):\n","        # input_img (batch_size)\n","        # x is the lstm input (batch_size, 199) where 199 is seqlen\n","        # label is the label (batch_size, 199) where 199 is seqlen\n","        # device = \"cpu\"/\"cuda:0\"\n","        # prediction_mode = True/False\n","\n","        batch_size = input_img.size()[0]\n","\n","        # LSTM hidden state initialization\n","        prev_state_h, prev_state_c = self.memegeneratorlstm.init_state(batch_size)\n","        prev_state_h = prev_state_h.to(device)\n","        prev_state_c = prev_state_c.to(device)\n","\n","        # store predictions and outputs\n","        predictions_arr = []\n","        output_tensor = torch.zeros((batch_size, 1, len(char2idx)))\n","        output_tensor = output_tensor.to(device)\n","\n","        lstm_input = torch.unsqueeze(x[:,0], dim = 1)\n","\n","        # for prediction only\n","        first_nonzero = (x == 0).nonzero(as_tuple=False)[0][1].item()\n","\n","        # Teacher forcing - feeding the target as the next input\n","        for t in range(0, x.size()[1]): # iterate until len of sequence\n","             # prediction size (batchsize, num_vocab)\n","             predictions, prev_state_h, prev_state_c = self.memegeneratorlstm(input_img, lstm_input, prev_state_h, prev_state_c)\n","\n","             # store lstm_output_tensor\n","             output_tensor = torch.cat([output_tensor, torch.unsqueeze(predictions, dim=1)], dim = 1)            \n","             # get one prediction\n","             one_prediction = torch.max(predictions, dim = 1).indices\n","             # save the prediction in list\n","             predictions_arr.append(one_prediction.detach().cpu().numpy())\n","\n","             if prediction_mode == False:\n","                 # using teacher forcing\n","                 lstm_input = torch.unsqueeze(label[:, t], dim = 1)\n","             else:\n","                 # only for batchsize = 1\n","                 # use teacher forcing for initial starter string\n","                 if t < first_nonzero - 1:\n","                    lstm_input = torch.zeros((1, 1)).long()\n","                    lstm_input[0] = x[0][t+1]\n","                 else:\n","                    # use prediction as previous output previous input\n","                    one_prediction = torch.unsqueeze(one_prediction, dim = 1)\n","                    lstm_input = one_prediction\n","        \n","        # remove the original zeros for output_tensor\n","        # output_tensor shape (batch_size, seqlen, numclasses)\n","        # predictions_arr shape (seqlen, batch_size)\n","        output_tensor = output_tensor[:,1:,:]\n","        predictions_arr = np.array(predictions_arr)\n","        predictions_arr = np.transpose(predictions_arr)\n","\n","        return output_tensor, predictions_arr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"locWezAqrTXf","colab_type":"code","colab":{}},"source":["def calculate_loss(pred, real, device):\n","    # pred shape (batch_size, seqlen, numclasses labels)\n","    # real shape (batch_size, seqlen)\n","\n","    batch_size = pred.size()[0]    \n","\n","    loss = torch.zeros(batch_size, requires_grad=True)\n","    loss = loss.to(device)\n","\n","    # iterate through batch_size\n","    for b in range(pred.size()[0]):\n","        # iterate through the sequence length\n","        for i in range(pred.size()[1]):\n","            # cross entropy loss combines log_softmax + NLL loss\n","            loss_ = F.cross_entropy(torch.unsqueeze(pred[b,i,:], dim=0), torch.unsqueeze(real[b,i], dim=0), ignore_index=char2idx[\"<pad>\"], reduction=\"mean\")\n","            loss[b] += loss_\n","\n","    # average out the loss along the sequence (not counting 0)\n","    num_nonzero = real > 0\n","    num_nonzero = num_nonzero.long()\n","    num_nonzero = torch.sum(num_nonzero, dim = 1)\n","\n","    # divide by number of nonzeros\n","    loss = torch.div(loss,num_nonzero)\n","    loss = torch.mean(loss)\n","\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5l8-5cprTiA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2hLdj1Q0DIt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYuXbszW0DPf","colab_type":"code","colab":{}},"source":["def evaluate_dict(gold_dict, pred_dict):\n","    sum_acc = 0\n","    total = 0\n","    \n","    # iterate through all items and get accuracy\n","    for key, value in pred_dict.items():  #array\n","        ground_truths = gold_dict[key]\n","        for idx, elem in enumerate(value):\n","            if ground_truths[idx] != 0:\n","                total += 1\n","                if ground_truths[idx] == value[idx]:\n","                    sum_acc += 1\n","\n","    eval_dict = {'acc': 100. * sum_acc / total }\n","    \n","    return eval_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRwLvrqg0DNF","colab_type":"code","colab":{}},"source":["def evaluate(model, dev_loader, dev_path, device, idx2char):\n","    \"\"\"Evaluates Model.\n","\n","    Args:\n","        Model (model): The model to evaluate\n","        dev_loader (loader): data loader as presented above\n","        dev_path (string): Path to eval npz file.\n","        device: \"cpu\" or \"cuda:0\" for gpu\n","        idx2char (dict): dictionary mapping integers to characters\n","    \"\"\"\n","    nll_meter = AverageMeter()\n","\n","    model.eval()\n","    pred_dict = {}\n","\n","    # get all true labels for ratings\n","    test_dataset = np.load(dev_path)\n","    true_labels = torch.from_numpy(test_dataset['label']).long()\n","    uniq_ids = torch.from_numpy(test_dataset['ids']).long()\n","    \n","    # gold_dict[id] = tensor of labels\n","    gold_dict = {}\n","    for ids in uniq_ids:\n","        gold_dict[ids.item()] = true_labels[ids.item()].detach().cpu().numpy()\n","    \n","    # put in evaluation mode\n","    with torch.no_grad(), tqdm.notebook.tqdm(total=len(dev_loader.dataset), position=1, leave=True) as progress_bar:\n","        for source, label, img, ids in dev_loader:\n","            batch_size = source.size(0) \n","\n","            # Setup for forward\n","            source = source.to(device) # (batchsize, 199) where 199 is max seqlen of text\n","            label = label.to(device)  # (batchsize, 199) where 199 is max seqlen of text \n","            img = img.to(device)  # (batchsize)\n","\n","            # Forward\n","            # output_tensor shape (batch_size, 199, # classes) -> Tensor\n","            # prediction_arr shape (batch_size, 199) -> Numpy array\n","            output_tensor, prediction_arr = model(img, source, label, device)\n","\n","            # calculate loss\n","            loss = calculate_loss(output_tensor, label, device)\n","            loss_val = loss.item()\n","\n","            nll_meter.update(loss_val, batch_size)\n","\n","            # Get maximum prediction for prediction\n","            preds = {}\n","            for idx, elem in enumerate(ids):\n","                preds[elem.item()] = prediction_arr[idx]\n","\n","            # Get maximum prediction for prediction\n","            pred_dict.update(preds)\n","\n","            # Log info\n","            progress_bar.update(batch_size)\n","            progress_bar.set_postfix(NLL=nll_meter.avg)\n","\n","    model.train()\n","    \n","    # return results\n","    results = evaluate_dict(gold_dict, pred_dict)\n","    results_list = [('NLL', nll_meter.avg),\n","                    ('acc', results['acc'])\n","                   ]\n","\n","    results = OrderedDict(results_list)\n","    return results, pred_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRjjU6Av6mWT","colab_type":"code","colab":{}},"source":["def visualize(tbx, pred_dict, eval_path, step, split, num_visuals):\n","      \"\"\"Visualize text examples to TensorBoard.\n","\n","      Args:\n","          tbx (tensorboardX.SummaryWriter): Summary writer.\n","          pred_dict (dict): dict of predictions of the form id -> pred.\n","          eval_path (string): Path to eval npz file.\n","          step (int): Number of examples seen so far during training.\n","          split (str): Name of data split being visualized.\n","          num_visuals (int): Number of visuals to select at random from preds.\n","      \"\"\"\n","\n","      if num_visuals <= 0:\n","          return\n","      if num_visuals > len(pred_dict):\n","          num_visuals = len(pred_dict)\n","\n","      # pick randomly from indexes\n","      visual_ids = np.random.choice(list(pred_dict), size=num_visuals, replace=False)\n","\n","      # get test dataset\n","      test_dataset = np.load(eval_path, allow_pickle=True)\n","      true_labels = test_dataset['label']\n","      test_source = test_dataset['source']\n","      test_img = test_dataset['img']\n","\n","      # iterate through index and append to tensorboard\n","      for i, id_ in enumerate(visual_ids):\n","          pred = pred_dict[id_]\n","          source = test_source[id_]\n","          label = true_labels[id_]\n","          img_name = test_img[id_]\n","\n","          # convert back to encodings\n","          source = [idx2char[elem] for elem in source]\n","          source = ''.join(source)\n","          label = [idx2char[elem] for elem in label]\n","          label = ''.join(label)\n","          pred = [idx2char[elem] for elem in pred]\n","          pred = ''.join(pred)\n","\n","          # need to replace <start>, <end>, <sep>, <pad> token for visualization purposes\n","          source = source.replace('<start>', 'START ')\n","          source = source.replace('<end>', ' END ')\n","          source = source.replace('<sep>', ' SEP ')\n","          source = source.replace('<pad>', ' PAD ')\n","          \n","          label = label.replace('<start>', 'START ')\n","          label = label.replace('<end>', ' END ')\n","          label = label.replace('<sep>', ' SEP ')\n","          label = label.replace('<pad>', ' PAD ')\n","\n","          pred = pred.replace('<start>', 'START ')\n","          pred = pred.replace('<end>', ' END ')\n","          pred = pred.replace('<sep>', ' SEP ')\n","          pred = pred.replace('<pad>', ' PAD ')\n","          \n","          img_name = idx2img[img_name]\n","\n","          tbl_fmt = (f'- **Source:** {source}\\n'\n","                    + f'- **Label:** {label}\\n'\n","                    + f'- **Prediction:** {pred}\\n'\n","                    + f'- **Img Name:** {img_name}')\n","          tbx.add_text(tag=f'{split}/{i+1}_of_{num_visuals}',\n","                      text_string=tbl_fmt,\n","                      global_step=step)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrvy1pX-aAaF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600474037529,"user_tz":240,"elapsed":41461,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"53206128-d150-4b0b-8b71-37fd07b8c853"},"source":["save_dir = 'gdrive/My Drive/MemeGenerator/save/train/baseline-03'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","log = get_logger(save_dir, 'baseline')\n","tbx = SummaryWriter(save_dir)\n","log.info(f'Using random seed 224 ...')\n","\n","# create checkpoint saver\n","saver = CheckpointSaver(save_dir,\n","                        max_checkpoints=5,\n","                        metric_name='acc',\n","                        maximize_metric='acc',\n","                        log=log)\n","\n","# create model and train\n","model = MemeGeneratorM2()\n","model = model.to('cuda:0')\n","model.train()\n","\n","# optimizer and smoothing\n","optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","ema = EMA(model, 0.999) # Exponentially Smooth parameters"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[09.19.20 00:07:07] Using random seed 224 ...\n","[09.19.20 00:07:07] Saver will maximize acc...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hp0qNjHEaAhv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["30539e5cdb0c461a90adc6d8cbd56d20","9d97de87b3024222a1252f8991c5a9eb","851d0e0b8d514e989aefece9a4fcd44d","fcdaf4d80c0843c5a2fc694af6ac0a01","10c194661386401d99bb34ab9e266410","3384862a305f4186a80fd6c8ca694c89","cb8627ae6ac448d69e5fada4afa86928","f4391d5bf02347f998db0bbf5c06a5c9","35308ebc710947728b82f1f064a878d2","fe4de7a51bda4a31a2552a7e2181af22","42d22e0c956748d4beb623a9cedd6a5c","3b610ceaa65e43619350f7a760f9cdb8","c0b9057d714a4267b1a889cff933c562","6feaba19337940b39d9cf17c5b9fb987","2e13a1de8a254a81bd43894322a21227","65eccd90cd554a71a8b029bbf2dddef4","b894da7e9ba147d99655a89ac64b6537","9ec61fcc675249b0bd1bbac89918dcc2","5ba63995889f42dfb1528b8296d0cc65","f1fe33c4c92649cabf05802c0065b148","9cfe0e0c778b46d284ab253b27acaff1","18c4994c87074a82b79964345726b8bc","8bc2326206b54b87bef076087c00dff0","5bb2773d67c64b158737c017c075568e","e22b02107997484496210feb79824016","af977c6d5c5c4ef6ad6c9623847c1960","c1c6eef2868f43289c83d0600a7aa933","d530605c76ea43c492d7440ba131adc5","7d9689b81965410e9caa7457aaedc807","c7a3fd5bbdbf4b1397b0ebe009086ef2","c6786fba8351493b82b9f2652e804b83","b595699deeb0436eaa50131054801813","a96fb27e8373493c9d56266632f210b1","73c888ff306b4cdfb4c527a8b35bc019","63c64fd5a38d4d8292c7a34dd0ca97bb","b8357e48d00a4726baf6307474543e6a","e65c03b3d95f43da85e7520b831903c5","e7ccdb38321b4a61a952d70b12770e1a","e586d163687e49108438171cd5d1fbf6","b9ff9765d9dd49cf94c7963fe8c590a9","11f3e5f738a74cae9025f934945424e4","810af9a64e684d6faaefa7c1afbd099e","75d6df3b736c4048aadf9550aad8a8ab","11ea7277c375410d89ac3c0c60823018","8d83f37abd3545fba66f5a42246127e8","1510a1078a0b4768bc07861162d0638d","95b6168b927545a9b1a95ceabf02de2c","9162ecec081d40758c7d60c96d0bbad0","0fde75d766cb47688a2c4d6183adec5b","d423007d5f514d57937c616f8cf97fa1","a453e98ea2fa47a399af593b29cbc8da","7b074653d51f472ba525cd4f77691739","7a9409c9c0914644bd51fa78de5ba2ac","e6ccbec5d1524c178d845b77594ff7fc","7bcf79c8419c45a2806efd2772b0de72","f3635e14f50f4dd89c18edfbcdc400c5","973477ae2c234469a7b6dfb19b2c01b7","98abd0cf329d45fbad46126f9aae7854","018b4982106c48a3b88f9cda1864e701","f347ce312a6f442a90aefb7fd82c178a","c151c54e64aa4fe28d471dd0e4091420","b853590b17304da9aab4259712eefa08","1ebddce01e494267a689e0dd0f715bb6","15a97f5992d8424ba3c3abc265ebaaf9","49fba5a1c4ad470088714236f664d6cf","eff7df095b8049119d76ccd6a0430632","67c1f359ab5a4b129297aaafaf51bafe","8b87d2ff2032490f81805e71323f5d8c","5787d56980ab477c920b372df7517bb7","42cd728197bc4acb8f4b449178a3f0fc","bfef253774724aee8c74c642af7e3ac9","5023def23931494ba0c473c6dc118d1b"]},"outputId":"370fb97d-2af6-4cdd-9955-5795d3a6fda1"},"source":["epoch = 0\n","step = 0\n","steps_till_eval = 30000 # evaluate model after 2000000 iterations\n","device = 'cuda:0'\n","\n","while epoch != 10:  # Num Epochs to train on \n","    epoch += 1\n","\n","    log.info(f'Starting epoch {epoch}...')\n","    with torch.enable_grad(), tqdm.tqdm(total=len(train_loader.dataset), position=0, leave=True) as progress_bar:\n","        for source, label, img, ids in train_loader:\n","            batch_size = source.size(0) \n","\n","            # Setup for forward\n","            source = source.to(device) # (batchsize, 199) where 199 is max seqlen of text\n","            label = label.to(device)  # (batchsize, 199) where 199 is max seqlen of text \n","            img = img.to(device)  # (batchsize)\n","            optimizer.zero_grad()\n","\n","            # Forward\n","            # output_tensor shape (batch_size, 199, # classes) -> Tensor\n","            # prediction_arr shape (batch_size, 199) -> Numpy array\n","            output_tensor, prediction_arr = model(img, source, label, device)\n","\n","            # calculate loss\n","            loss = calculate_loss(output_tensor, label, device)\n","            loss_val = loss.item()\n","\n","            # Backward\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), 1)  # clip max gradients to 1\n","            optimizer.step()\n","            ema(model, step // batch_size)\n","\n","            # Log info\n","            step += batch_size\n","            progress_bar.update(batch_size)\n","            progress_bar.set_postfix(epoch=epoch, NLL=loss_val)\n","            \n","            tbx.add_scalar('train/NLL', loss_val, step)\n","            tbx.add_scalar('train/LR',\n","                             optimizer.param_groups[0]['lr'],\n","                             step)\n","            \n","            steps_till_eval -= batch_size\n","            if steps_till_eval <= 0:\n","                steps_till_eval = 30000\n","\n","                # Evaluate and save checkpoint\n","                log.info(f'Evaluating at step {step}...')\n","                ema.assign(model)\n","                results, pred_dict = evaluate(model, dev_loader, 'gdrive/My Drive/MemeGenerator/dataset_final_m2/test.npz', device, idx2char)\n","                \n","                saver.save(step, model, results['acc'], device)\n","                ema.resume(model)\n","\n","                # Log to console\n","                results_str = ', '.join(f'{k}: {v:05.2f}' for k, v in results.items())\n","                log.info(f'Dev {results_str}')\n","\n","                # Log to TensorBoard\n","                log.info('Visualizing in TensorBoard...')\n","                for k, v in results.items():\n","                      tbx.add_scalar(f'dev/{k}', v, step)  \n","\n","                visualize(tbx, pred_dict, eval_path='gdrive/My Drive/MemeGenerator/dataset_final_m2/test.npz', step=step, split='dev', num_visuals=30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/83266 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 00:07:17] Starting epoch 1...\n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 30016/83266 [41:01<1:17:09, 11.50it/s, NLL=1.6, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 00:48:19] Evaluating at step 30016...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30539e5cdb0c461a90adc6d8cbd56d20","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"," 36%|███▌      | 30016/83266 [41:20<1:17:09, 11.50it/s, NLL=1.6, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 30016/83266 [42:24<1:17:09, 11.50it/s, NLL=1.6, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 00:49:42] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_30016.pth.tar\n","[09.19.20 00:49:42] New best checkpoint at step 30016...\n","[09.19.20 00:49:42] Dev NLL: 01.52, acc: 55.28\n","[09.19.20 00:49:42] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 60032/83266 [1:23:47<31:53, 12.15it/s, NLL=1.47, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 01:31:05] Evaluating at step 60032...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35308ebc710947728b82f1f064a878d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 72%|███████▏  | 60032/83266 [1:24:00<31:53, 12.15it/s, NLL=1.47, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 60032/83266 [1:25:06<31:53, 12.15it/s, NLL=1.47, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 01:32:24] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_60032.pth.tar\n","[09.19.20 01:32:24] New best checkpoint at step 60032...\n","[09.19.20 01:32:24] Dev NLL: 01.39, acc: 58.97\n","[09.19.20 01:32:24] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 83266/83266 [1:57:09<00:00, 11.84it/s, NLL=1.14, epoch=1]\n","  0%|          | 0/83266 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 02:04:27] Starting epoch 2...\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 6784/83266 [09:14<1:43:39, 12.30it/s, NLL=1.28, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 02:13:42] Evaluating at step 90050...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b894da7e9ba147d99655a89ac64b6537","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r  8%|▊         | 6784/83266 [09:30<1:43:39, 12.30it/s, NLL=1.28, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 6784/83266 [10:34<1:43:39, 12.30it/s, NLL=1.28, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 02:15:01] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_90050.pth.tar\n","[09.19.20 02:15:02] New best checkpoint at step 90050...\n","[09.19.20 02:15:02] Dev NLL: 01.33, acc: 60.49\n","[09.19.20 02:15:02] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 44%|████▍     | 36800/83266 [50:56<1:03:41, 12.16it/s, NLL=1.34, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 02:55:24] Evaluating at step 120066...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e22b02107997484496210feb79824016","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 44%|████▍     | 36800/83266 [51:10<1:03:41, 12.16it/s, NLL=1.34, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 44%|████▍     | 36800/83266 [52:18<1:03:41, 12.16it/s, NLL=1.34, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 02:56:45] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_120066.pth.tar\n","[09.19.20 02:56:45] New best checkpoint at step 120066...\n","[09.19.20 02:56:45] Dev NLL: 01.29, acc: 61.46\n","[09.19.20 02:56:45] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 66816/83266 [1:34:05<24:03, 11.40it/s, NLL=1.25, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 03:38:33] Evaluating at step 150082...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a96fb27e8373493c9d56266632f210b1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 80%|████████  | 66816/83266 [1:34:20<24:03, 11.40it/s, NLL=1.25, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 66816/83266 [1:35:28<24:03, 11.40it/s, NLL=1.25, epoch=2]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 03:39:56] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_150082.pth.tar\n","[09.19.20 03:39:56] New best checkpoint at step 150082...\n","[09.19.20 03:39:56] Dev NLL: 01.27, acc: 62.14\n","[09.19.20 03:39:56] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 83266/83266 [1:59:12<00:00, 11.64it/s, NLL=0.968, epoch=2]\n","  0%|          | 0/83266 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 04:03:39] Starting epoch 3...\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▋        | 13568/83266 [19:02<1:31:16, 12.73it/s, NLL=1.13, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 04:22:42] Evaluating at step 180100...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11f3e5f738a74cae9025f934945424e4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 16%|█▋        | 13568/83266 [19:20<1:31:16, 12.73it/s, NLL=1.13, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▋        | 13568/83266 [20:20<1:31:16, 12.73it/s, NLL=1.13, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 04:24:00] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_180100.pth.tar\n","[09.19.20 04:24:00] New best checkpoint at step 180100...\n","[09.19.20 04:24:00] Removed checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_30016.pth.tar\n","[09.19.20 04:24:00] Dev NLL: 01.25, acc: 62.57\n","[09.19.20 04:24:00] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 52%|█████▏    | 43584/83266 [1:00:17<53:16, 12.41it/s, NLL=1.39, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 05:03:57] Evaluating at step 210116...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fde75d766cb47688a2c4d6183adec5b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 52%|█████▏    | 43584/83266 [1:00:30<53:16, 12.41it/s, NLL=1.39, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 52%|█████▏    | 43584/83266 [1:01:34<53:16, 12.41it/s, NLL=1.39, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 05:05:14] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_210116.pth.tar\n","[09.19.20 05:05:14] New best checkpoint at step 210116...\n","[09.19.20 05:05:14] Removed checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_60032.pth.tar\n","[09.19.20 05:05:14] Dev NLL: 01.24, acc: 62.91\n","[09.19.20 05:05:14] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 88%|████████▊ | 73600/83266 [1:43:51<14:12, 11.34it/s, NLL=1.18, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 05:47:31] Evaluating at step 240132...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"973477ae2c234469a7b6dfb19b2c01b7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 88%|████████▊ | 73600/83266 [1:44:10<14:12, 11.34it/s, NLL=1.18, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 88%|████████▊ | 73600/83266 [1:45:18<14:12, 11.34it/s, NLL=1.18, epoch=3]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 05:48:57] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_240132.pth.tar\n","[09.19.20 05:48:57] New best checkpoint at step 240132...\n","[09.19.20 05:48:57] Removed checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_90050.pth.tar\n","[09.19.20 05:48:57] Dev NLL: 01.23, acc: 63.13\n","[09.19.20 05:48:57] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 83266/83266 [1:59:26<00:00, 11.62it/s, NLL=0.704, epoch=3]\n","  0%|          | 0/83266 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 06:03:05] Starting epoch 4...\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▍       | 20352/83266 [29:42<1:33:04, 11.27it/s, NLL=1.1, epoch=4]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 06:32:48] Evaluating at step 270150...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49fba5a1c4ad470088714236f664d6cf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4383.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 24%|██▍       | 20352/83266 [30:00<1:33:04, 11.27it/s, NLL=1.1, epoch=4]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▍       | 20352/83266 [31:09<1:33:04, 11.27it/s, NLL=1.1, epoch=4]"],"name":"stderr"},{"output_type":"stream","text":["[09.19.20 06:34:15] Saved checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_270150.pth.tar\n","[09.19.20 06:34:15] New best checkpoint at step 270150...\n","[09.19.20 06:34:15] Removed checkpoint: gdrive/My Drive/MemeGenerator/save/train/baseline-03/step_120066.pth.tar\n","[09.19.20 06:34:15] Dev NLL: 01.23, acc: 63.35\n","[09.19.20 06:34:15] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████▏    | 42720/83266 [1:03:22<54:38, 12.37it/s, NLL=1.07, epoch=4]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-XAoMvS4aAfr","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}